WHY DEVOPS : To deliver the applications very speedily.

SDLC : SOFTWARE DEVELOPMENT LIFECYCLE

HUMAN: 
infant
toddler
child
teenager
adult
old


TEAMS: Development + Operations
plan
code
build
test
deploy
operate
monitor

Deployment: Process of installing Application to server.
Here DevOps is going to automate the SDLC.

GIT
GITHUB
MAVEN
JENKINS
ANSIBLE
DOCKER
DOCKER SWARM
K8S
KOPS
TERRAFORM
PROMETHEUS 
GRAFANA 
JFORG
NEXUS
SONARQUBE




COURSE : DEVOPS WITH AWS
FREE: LINUX

DURATION: 2.5 MONTHS
DAILY: 4:30 - 6 PM
FEE: 10K (REC: 6 K)
PROJECTS: 5
TOOLS: 18
EXP: 3

===========================================================

DEPLOYMENT: Process of installing the application to server.

server: which serves the services to user
application: a collection of services 



SOFTWARE ARCHITECTURES: its a blue print of application.
TYPES:
1. ONE TIER
2. TWO TIER
3. THREE TIER
4. N TIER


TIER = SERVER = LAYER

1. WEB SERVER
2. APP SERVER
3. DB SERVER

WEB SERVER:
AKA	: PRESENTATION LAYER
PURPOSE	: TO SHOW THE APP
LAYER	: TOP LAYER
WHAT	: FRONT END CODE
EX	: HTML, CSS, JS -------
WHO	: UI/UX DEV

APP SERVER:
AKA	: BUSINESS/LOGIC LAYER
PRUPOSE	: TO USE THE APP
LAYER	: MIDDLE LAYER
WHAT	: BACKEND CODE
EX	: JAVA, PYTHON, C, C#, .NET ---
WHO	: BACKEND DEV

DATABASE SERVER:
AKA	: DB LAYER
PURPOSE	: TO STORE & RETRIVE DATA
LAYER	: LAST LAYER
WHAT	: DB LANGAUGES
EX	: MYSQL, SQL, PROSTGRES, ORACLE ---
WHO	: DBA, DBD


1. ONE TIER ARCHITECTURE: STAND-ALONE APPS

ALL 3 LAYERS WILL BE ON LOCAL
IT DOES NOT REQUITED INTERNET CONNECTION
NOTE: THESE APP WILL WORK ON OUR PCS ONLY.

EX: VLC

2. TWO TIER ARCHITECTURE: CLIENT-SERVER APPS 

WEB, APP WILL BE ON LOCAL & DB WILL BE ON INTERNET.
APP WILL BE DOWNLOADED TO LOCAL.
IT WILL REQUIRE INTERNET CONNECTION.

EX: BANKING APPS

3. THREE TIER ARCHITECTURE: WEB APPS

ALL 3 LAYERS WILL NOT BE ON LOCAL.
APPLICATION SIMPLY WE CAN USE FROM INTERNET.

EX: FB, IG, WAHTSAPP, SWIGGY, YOUTUBE

44.211.42.99:8080

==============================================================================

SERVER: which serves the services to user (client).

TYPES OF SERVER:
1. Web Server	: to show the app
2. App Server	: to use the app
3. DB Server	: to store & retrive data


HOW TO CREATE A SERVER:
1. CLOUD	: Data Centers
2. PHYSICAL	: On-Prem
3. VIRTUAL	: Laptops

CLOUD SERVER: create & use
Maintainace: AWS


HOW TO CREATE A CLOUD SERVER:
CLOUD ACCOUNT: AWS 

AWS	: EC2 INSTANCE

EC2: ELASTIC COMPUTE CLOUD
NOTE: SERVER IS A BIG COMPUTER.

HOW MANY STEPS TO CREATE EC2: 7 STEPS

SETP-1: Tags
Name for the servers

STEP-2: AMI (AMAZON MACHINE IMAGE)
OPERATING SYSTEM, PACKAGES 

SETP-3: INSTANCE TYPE
CPU & RAM 
T2.MICRO: 1 CPU & 1GB RAM (FREE)

STEP-4: KEY-PAIR
FOR LOGIN PURPOSE
1. PUBLIC KEY: AWS
2. PRIVATE KEY: USER -- > (PEM,PPK)

STEP-5: NETWORK

VPC: VIRTUAL PRIVATE CLOUD
SG : PORTS (TO ACCESS SERVICES & APPS)

SSH: 22 -- > TO COMMUNICATE WITH SERVER
(0-65535)


SETP-6: STORAGE
ELASTIC BLOCK STORAGE (EBS)
STORE OS FILES, APP CODE, APP DATA
DEFAULT: 8 GB
MAX    : 64 TB

STEP-7: SUMMARY 


github.com/RAHAMSHAIK007/syllabus.git

devops with aws


======================================================================

HARDWARE COMMANDS:
cat - to show content in a file

cat /proc/cpuinfo	: to show cpu information
lscpu			: to show cpu information
cat /proc/meminfo	: to show ram information
lsmem			: to show ram information
fdisk -l		: to show ebs information
lsblk			: to show ebs information
free -m			: to show ram details
yum install lshw -y	: yum: package manager install: action lshw: package
lshw			: to show the complete info of hardware.



INSTALL WEB SERVER:

yum install httpd -y
by default when we download service it will be on stopped state.
systemctl start httpd
systemctl status httpd
cd /var/www/html/   --- > this path will store front-end code

SCENARIO BASED:
how to troubleshoot you webserver.
1. check status is running or not


fee: 10 k
rec: 6k
tools: 18
devops, aws, linux
5 projects
3 years

COMMANDS:
FILE COMMANDS:


touch file1		: to create a file
ls/ll			: to list the files
cat file1		: to print the content of a file
more file1		: to print the content of a file
cat>>file1		: to insert the content
enter + ctrl d		: to save and quit
cp file1 file2		: to copy the content from file1 to file3
mv file1 raham		: to move/rename a file
rm file1		: to remove a file
rm file2 -f		: to remove a file forcefully
rm * -f			: to remove all files at a time
touch file{1..20}	: to create file1 to file20
rm file{6..20} -f	: to remove file6 to file20
wc file1		: to print num of lines, words and charcters
head file1		: to print top 10 lines of a file
head -7 file1		: to print top 7 lines of a file
head -12 file1		: to print top 12 lines of a file
tail file1		: to print bottom 10 lines of a file
tail -7 file1		: to print bottom 7 lines of a file
tail -12 file1		: to print bottom 12 lines of a file
sed -n '5,15p' file2	: to print line 5 to line 15 of a file


GREP: Global Regular Expression Print
to search the words 

cat file1

hai all my name is raham
hai my name is raham
im teaching devops
raham is from hyderabad
he is working for tcs


grep raham file2		: to search for raham in file2
grep RAHAM file2 -i		: -i -- > to Avoid case sensitivity
grep RAHAM file2 -ic		: -c -- > to print count
grep RAHAM file2 -iv		: -v -- > to print lines without raham
grep 'devops\|raham\|tcs' file1 : to search for multiple words

========================================================================================
EDITORS:
To edit the content in a file
ex: vim/vi, nano

we have 3 modes in vim editor
1. command mode
2. insert mode
3. save mode

NOTE:
i   : to insert content
esc : after inserting content


3. SAVE MODE:
:w	: to save
:q	: to quit
:wq	: save & quit
:wq!	: forceful save & quit

2. INSERT MODE:
i	: to insert the content
I	: starting of line
A	: Ending of line
O	: create new line above existing
o	: create new line below existing

1. COMMAND MODE:

shift g		: bottom of file
gg		: top of file
14gg		: to go for 14th line
8gg		: to go for 8th line
yy		: copies single line
3yy		: copies three line
p		: paste the lines 
3p		: paste the 3 times 
dd		: to delete the single line
3dd		: to delete the three line
u		: to undo
:set number	: to print line numbers
/word		: to search for a word

SED: STREAM EDITOR
to replace words inside a file

sed -i 's/word1/word2/g' file1	: to replace word1 with word2
sed -i 's/raham/vijay/g' file1  : to replace raham as vijay

sed -i 's/vijay/raham/g; s/linux/devops/g' file1 : to replace multiple words
sed -i '2c hai all' file1	: to replace 2nd line 

======================================================================================================================================
GIT : GLOBAL INFORMATION TRACKER
SOURCE CODE -- > CODE USED TO CREATE AN APPLICATION.

GIT ALSO CALLED AS VCS/SCM.

VCS: VERSION CONTROL SYSTEM
TO STORE EACH VERSION OF CODE SEPARATELY.

V1 -- > 1 FEATURES -- > 100 LINES   -- > FOLDER-1
V2 -- > 2 FEATURES -- > 200 LINES   -- > FOLDER-2
V3 -- > 3 FEATURES -- > 300 LINES   -- > FOLDER-3

WHY TO STORE SEPERATELY: FOR BACKUP 
ROLL BACK: GOING BACK TO PREVIOUS VERSION
V2 -- > V1
WHY WE NEED TO ROLLBACK: IF CURRENT VERSION IS NOT WORKING PROPERLY

SCM: SOURCE CODE MANAGEMENT

GIT:
Git is used to track the files.
It will maintain multiple versions of the same file.
It is platform-independent.
It is free and open-source.
They can handle larger projects efficiently.
It is 3rd generation of vcs.
it is written on c programming
it came on the year 2005

INDEX.HTML  
V1 -- > 1O LINES
V2 -- > 20 LINES
V3 -- > 30 LINES

CVCS: CENTRALIZED VERSION CONTROL SYSTEM
IT CAN STORE CODE ON A SINGLE REPO.
EX: SVN

DVCS: DISTRIBUTED VERSION CONTROL SYSTEM
IT CAN STORE CODE ON MULTIPLE REPO.
EX: GIT

ARCHITECTURE/STAGES OF GIT:
GIT WILL BE HAVING 3 STAGES:

1. WORKING DIRECTORY: Where we write the code.
2. STAGING AREA: where we track the code.
3. REPOSITORY: where we store the tracked code.

INSTALLING GIT:
yum install git -y
yum: pacakge manager
install: action
git: tool 
-y: yes
git -v       : to check the git version
git init     : to initialize the .git repo (local repo)
NOTE: without .git we can't run git commands.



mkdir raham
cd raham
git init

touch file1		: to create a file
git add file1		: to track the file
git commit -m "commit-1" file1 : to commit the file
git log			: to show commits history
git log --oneline	: to show commits on single line
git log --oneline -2	: to show last 2 commits on single line

HISTORY:
    1  yum install git -y
    2  git -v
    3  ll
    4  ll -a
    5  git init
    6  ll -a
    7  touch file1
    8  git status
    9  mkdir raham
   10  cd raham/
   11  touch file1
   12  git status
   13  git init
   14  git status
   15  git add file1
   16  git status
   17  git commit -m "commit-1" file1
   18  git status
   19  touch file2
   20  git status
   21  git add file2
   22  git status
   23  git commit -m "commit-2" file2
   24  touch file3
   25  git add file3
   26  git commit -m "commit-3" file3
   27  touch file4
   28  git add file4
   29  git commit -m "commit-4" file4
   30  git log
   31  git log --oneline
   32  git log --oneline -2
   33  git log --oneline -3
   34  mkdir abcd
   35  cd abcd/
   36  git status
   37  cd
   38  mkdir abcd
   39  cd abcd/
   40  git init
   41  history

=================================================================================================
BRANCH: 
It an individual line of development for the code.
in real time multiple developers will be working on code.
each developer will write their code on their own branches.
Initially they create their branches on local laptop.
at the end, all developers will push the branch from local to github.
Default branch in git is MASTER.
NOTE: without a commit we cant see any branch in git

git branch			: to show list of branches
git branch branch_name		: to create a new branch
git checkout branch_name	: to switch to a branch
git checkout -b branch_name	: to create and switch to a branch at a time
git branch -m old_name new_name	: to rename a branch
git branch -D branch_name 	: to delete a branch



PROCESS:
touch index.html
git add index.html 
git commit -m "commit-1" index.html 
git branch

git branch movies
git checkout movies
touch movies{1..5}
git add movies*
git commit -m "movies commits" movies*

git branch recharge
git checkout recharge
touch recharge{1..5}
git add recharge*
git commit -m "recharge commits" recharge*

git checkout -b train
touch train{1..5}
git add train*
git commit -m "train commits" train*

git checkout -b dth
touch dth{1..5}
git add dth*
git commit -m "dth commits" dth*


GITHUB: 
it's a centralized/remote repository where all developers will push the code.
here we can merge all developer's code.
if we lost the code on local still code will be on github.

NOTE: Support for password authentication was removed on August 13, 2021.
We need to give tokens insted of password.

create a github account and create a repo

git remote add origin https://github.com/vishalreddy111/paytm.git

profile -- > settings -- > developer settings -- > Personal access token -- > classic -- > generate new token -- > classic -- > name: paytm -- > select 6 scopes -- > generate 

NOTE: token can be visible only once.

git push origin master
username: vishalreddy111
password: give token

git push origin movies
username: vishalreddy111
password: give token

git push origin recharge
username: vishalreddy111
password: give token

git push origin train
username: vishalreddy111
password: give token

git push origin dth
username: vishalreddy111
password: give token


USER CONFIGURATION:
git config user.name "raham"
git config user.email "raham@gmail.com"

GIT RESTORE:
1. used to recover deleted file
git restore file_name
2. used to untrack the tracked file
git restore --staged file_name

HISTORY:
    1  yum install git -y
    2  mkdir paytm
    3  cd paytm/
    4  git status
    5  git init
    6  git branch
    7  touch index.html
    8  git add index.html
    9  git commit -m "commit-1" index.html
   10  git log
   11  git branch
   12  git config user.name "raham"
   13  git config user.email "raham@gmail.com"
   14  git branch movies
   15  git branch
   16  git checkout movies
   17  git branch
   18  touch movies{1..5}
   19  git add movies*
   20  git commit -m "movies commits" movies*
   21  ll
   22  git branch
   23  git branch recharge
   24  git checkout recharge
   25  ll
   26  touch recharge{1..5}
   27  git add recharge*
   28  git commit -m "recharge commits" recharge*
   29  git branch
   30  git checkout -b train
   31  git branch
   32  touch train{1..5}
   33  git add train*
   34  git commit -m "train commits" train*
   35  git checkout -b dth
   36  git branch
   37  ll
   38  touch dth{1..5}
   39  git add dth*
   40  git commit -m "dth commits" dth*
   41  git remote add origin https://github.com/vishalreddy111/paytm.git
   42  ll -al
   43  git branch
   44  git push origin master
   45  git push origin movies
   46  git push origin recharge
   47  git push origin train
   48  git push origin dth
   49  git branch
   50  git branch -m dth abc
   51  git branch
   52  git branch -m abc dth
   53  git branch
   54  git branch -D train
   55  git branch
   56  git checkout train
   57  ll
   58  git branch
   59  git branch -D movies
   60  git checkout movies
   61  ll
   62  history
======================================================================
GIT CLONE: used to download repo from github to local.
git clone https://github.com/vishalreddy111/paytm.git

GIT FORK:  used to download repo from one github account to another.

GIT MERGE: used to add files blw two branches
git checkout master
git merge movies -- > all the files from movies branch will merge to master branch
git merge recharge

GIT REBASE: used to add files blw two branches
git rebase train
git rebase dth

MERGE VS REBASE:
merge for public repos, rebase for private 
merge stores history, rebase will not store the entire history
merge will show files, rebase will not show files


GIT REVERT: to undo git merge
unfortunately, if we add files between two branches we can get those files back.

git revert dth (it will open a file just quit from file)

GIT STASH: to hide the files temporarily.
we can stash tacked files only.
if the file is committed we can't stash them.

git stash	: to hide the files
git stash apply	: to get the hidden files back
git stash list	: to show list of stashes
git stash clear	: to delete all stashes
git stash pop	: to delete last stash only.


GIT PULL : used to get latest changes from github to local
git pull origin master

Note: without changes form github to git it wont work.

PUSH: sending code from git to github.
PULL: getting code form github to git.

GIT FECTCH: to show the difference of content form files from github to git.
git fetch 



HISTORY:
    1  yum install git -y
    2  git clone https://github.com/vishalreddy111/paytm.git
    3  ll
    4  cd d
    5  cd paytm/
    6  git branch
    7  git checkout movies
    8  git branch
    9  ls
   10  git checkout train
   11  git checkout recharge
   12  git branch
   13  git checkout dth
   14  git branch
   15  ll
   16  git checkout master
   17  ll
   18  git merge movies
   19  ll
   20  git branch
   21  git merge recharge
   22  ll
   23  git rebase train
   24  ll
   25  git rebase dth
   26  ll
   27  git revert dth
   28  ll
   29  git revert train
   30  ll
   31  cd
   32  mkdir raham
   33  cd raham/
   34  cd
   35  cd paytm/
   36  ll
   37  touch file1 file2
   38  git add file1 file2
   39  git status
   40  git stash
   41  ll
   42  git stash apply
   43  ll
   44  git status
   45  git stash list
   46  git stash
   47  git stash list
   48  git stash apply
   49  ll
   50  git stash list
   51  git stash pop
   52  git stash list
   53  git stash clear
   54  git stash list
   55  git restore --staged file1
   56  git stash list
   57  git status
   58  git stash
   59  ll
   60  git branch -D train
   61  ll
   62  git checkout master
   63  ll
   64  git pull
   65  ll
   66  git pull origin master
   67  git config pull.rebase false
   68  git pull origin master
   69  ll
   70  git pull origin master
   71  git config pull.rebase true
   72  git pull origin master
   73  ll
   74  cd
   75  ll
   76  rm -rf *
   77  git clone https://github.com/vishalreddy111/paytm.git
   78  cd paytm/
   79  ll
   80  cat index.html
   81  git pull origin master
   82  cat index.html
   83  git pull origin master
   84  ll
   85  cat index.html
   86  git pull origin master
   87  history

======================================================================================


CHERRY-PICK: used to merge file blw branches based on specific commits.
instead of merging all files from one branch to another 
it will merge only few files.

git cherry-pick commit_id

.GITIGNORE: to ignore the files
if we dont want to track and commit files we can put this files here.

touch raham{1..5}
git status

vim .gitignore
raham*
:wq

git status

MERGE CONFLICTS:
it will rise when we merge 2 different branches with same files.
How to resolve: Manually 

vim index.html
im dev-1 writing index.html on branch-1
git add index.html
git commit -m "dev-1 commits" index.html
git branch -m master branch1

vim index.html
im dev-2 writing index.html on branch-2
git add index.html
git commit -m "dev-2 commits" index.html

vim index.html
im dev-1 writing index.html on branch-1
new line
git add index.html
git commit -m "dev-1 2nd commits" index.html
git merge branch2


vim index.html
git add index.html
git commit -m "merge commits"


GIT SHOW: To show the files attached to commits.
git show commit_id


GIT RESTORE: used to untrack the tracked file.
used to restore the deleted file.

touch abcd
git add abcd
git status
git restore file


====================================================================

MAVEN:

raw chicken -- >  clean  --> marnet -- > ingredients -- > Chicken Biryani
raw code    -- > build   -- > test  -- > artifact -- > Deployment

ARTIFACT: its final product of our code.
developers will give raw code that code we are going to convert into artifact.

TYPES:
1. jar	: Java Archive       : Backend code
2. war	: Web Archive	     : Frontend code + Backend code
3. ear	: Enterprise Archive : jar + war 

JAR FILE:

.java -- > compile -- > .class -- > .jar file

.java	: basic raw
.class	: executable file
.jar	: artifact

all the artifacts are going to created by a build too1.

MAVEN:
Maven is the build tool.
its a free and opensource.
build: process of adding the libs & dependencies to code.
its is also called as Project managemnt too1.
it will manage the complete structure of the project.
the main file in the maven tool is POM.XML

POM.XML: its a file which consist of complete project information.
Ex: name, artifact, tools, libs, dep --------

POM: PROJECT OBJECT MODEL
XML: EXTENSIBLE MARKUP LANGUAGE

WHO GIVE POM.XML : DEVELOPERS
dev will give both code and pom.xml in github

maven is written on java by apache software foundation.
supports: JAVA-1.8.0
year: 2004
home path: .m2


PRATCICAL PART:
1. CREATE AN EC2 INSTANCE AND CONNECT
2. yum install git java-1.8.0-openjdk maven -y
3. git clone https://github.com/devopsbyraham/jenkins-java-project.git
4. cd jenkins-java-project


MAVEN LIFECYCLE:
GOALS : a command used to run a task.
Goals refers pom.xml to execute.


PLUGIN: its a small software with makes our work automated.
insted of downloading tools we can donwload plugins.
this plugins will donwload automatically when we run goals.



1. mvn compile : used to compile the code (.java [src] -- > .class [target])
2. mvn test    : used to test the code    (.java [test] -- > .class [target])
3. mvn package : used to create artifact 
4. mvn install : used to copy artifact to .m2 (project folder -- > .m2)
5. mvn clean   : to delete the target folder
6. mvn clean package: compile -- > install


PROBLEMS WITHOUT MAVEN:
1. we cant create artifacts.
2. We cant create project structure.
3. we cant build and deploy the apps.


MAVEN VS ANT:
1. MAVEN IS BUILD & PROJECT MANAGEMNT, ANT IS ONLY BUILD TOOL
2. MAVEN HAS POM.XML, ANT HAS BUILD.XML
3. MAVEN HAS A LIFECYCLE, ANT WILL NOT HAVE LIFECYCLE
4. MAVEN PLUGINS ARE REUSABLE, ANT SCRIPTS ARE NOT RESUEABLE.
5. MAVEN IS DECLARATIVE, ANT IS PROCEDURAL.

PROGRAMMING VS BUILD:

JAVA	: MAVEN
PYTHON	: GRADLE
.NET	: VS CODE
C, C#	: MAKE FILE
node.js	: npm

ALTERNETIAVES: 
ANT, GRADLE for java projects.

HISTORY:
    1  yum install git java-1.8.0-openjdk maven -y
    2  mvn -v
    3  git clone https://github.com/devopsbyraham/jenkins-java-project.git
    4  ll
    5  cd jenkins-java-project/
    6  ll
    7  yum install tree -y
    8  tree
    9  mvn compile
   10  tree
   11  ll
   12  mvn test
   13  tree
   14  mvn package
   15  tree
   16  mvn install
   17  ll /root/.m2/repository/in/RAHAM/NETFLIX/1.2.2/
   18  ll
   19  mvn clean
   20  ll
   21  mvn clean packge
   22  mvn clean package
   23  tree
   24  ll
   25  mvn clean
   26  mvn package
   27  cat pom.xml
   28  ll
   29  cd
   30  mvn clean
   31  ll
   32  cd jenkins-java-project/
   33  mvn clean
   34  mvn compile
   35  mvn test
   36  history

==================================================

JENINS IS A CI/CD TOOL.
REALITY: JENKINS IS ONLY FOR CI.

CI : CONTINOUS INTEGRATION : CONTINOUS BUILD + CONTINOUS TEST (OLD CODE WITH NEW CODE)

DAY-1: 100 LINES : BUILD + TEST
DAY-2: 200 LINES : BUILD + TEST
DAY-3: 300 LINES : BUILD + TEST

BEFORE CI:
MANUAL PROCESS
TIME WASTE

AFTER CI:
AUTOMATED PROCESS
TIME SAVING

CD: CONTINOUS DELIVERY/DEPLOYMENT

ENV:
PRE-PROD/NON-PROD:
DEV	: developers
QA	: testers
UAT	: clients

LIVE/PROD ENV:
PROD	: users


CONTINOUS DELIVERY: Deploying the application to producion in manual.
CONTINOUS DEPLOYMENT: Deploying the application to producion in automatic.


PIPELINE: 

WAKEUP -- > DAILY ACTIVITIES -- > BREAKFAST -- > LUNCH -- > CLASS
CODE -- > COMPILE -- > TEST -- > ARTIFACT -- > DEPLOY

SETP BY STEP EXECUTION OF A PROCESS.
SERIES OF EVENTS INTERLINKED WITH EACHOTHER.


JENKINS: 
ITS A FREE AND OPEN-SOURCE TOOL.
JENKINS WRITTEN ON JAVA.
IT IS PLATFORM INDEPENDENT.
IT CONSIST OF PLUGINS.
WE HAVE COMMUNITY SUPPORT.
IT CAN AUTOMATE ENTIRE SDLC.
IT IS OWNED BY SUN MICRO SYSTEM AS HUDSON.
HUDSON IS PAID VERSION.
LATER ORACLE BROUGHT HUDSON AND MAKE IT FREE.
LATER HUDSON WAS RENAMED AS JENINS.
INVENTOR: Kohsuke Kawaguchi
PORT NUMBER: 8080
JAVA: JAVA-11/17
DEFAULT PATH: /var/lib/jenkins

ALTERNATIVES:
BAMBOO, GO CI, CIRCLE CI, TARVIS, SEMAPHORE, BUDDY BUILD MASTER, GITLAB, HARNESS
ARGOCD -----

CLOUD: AWS CODEPIPELINE, AZURE PIPLEINE ---------------------



SETUP: Craete an EC2 and Include all traffic in sg

#STEP-1: INSTALLING GIT JAVA-1.8.0 MAVEN 
yum install git java-1.8.0-openjdk maven -y

#STEP-2: GETTING THE REPO (jenkins.io --> download -- > redhat)
sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key

#STEP-3: DOWNLOAD JAVA11 AND JENKINS
amazon-linux-extras install java-openjdk11 -y
yum install jenkins -y
update-alternatives --config java

#STEP-4: RESTARTING JENKINS (when we download service it will on stopped state)
systemctl start jenkins.service
systemctl status jenkins.service

CONNECT:
copy-public-ip:8080 (browser)
cat /var/lib/jenkins/secrets/initialAdminPassword (server)
paster password on browser -- > installing plugins --- > user details -- > start


JOB: it is used to perform task.
to do any work or task in jenkins we need to create a job.

to run commands we need to select execute shell on build steps.

build now: to run job
workspace: place where our job outputs will store

CREATING A JOB:
NEW ITEM -- > NAME: ABC -- > FREESTYLE -- > OK -- > SCM -- > GIT -- > REPOURL: https://github.com/devopsbyraham/jenkins-java-project.git -- >Build Steps -- > ADD Build Steps -- > Execute shell -- > mvn clean package -- > save -- > build now

WORKSPACE: where your job output is going to be stored
Default: /var/lib/jenkins/workspace


CUSTOM WORKSPACE: storing the jobs output on our own folders
cd 
mkdir raham
cd /
chown jenkins:jenkins /root
chown jenkins:jenkins /root/raham

Note: for every service user will be creatd by default

JOB -- > CONFIGURE -- > ADVNACE -- > Use custom workspace -- > /root/raham
-- > save -- > build now

HISTORY:
 1  yum install git java-1.8.0-openjdk maven -y
    2  sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo
    3    sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key
    4
    5  amazon-linux-extras install java-openjdk  -y
    6  amazon-linux-extras install java-openjdk11  -y
    7  yum install jenkins -y
    8  java -version
    9  update-alternatives --config java
   10  java -version
   11  systemcl start jenkins
   12  systemctl start jenkins
   13  systemctl status jenkins
   14  cat /var/lib/jenkins/secrets/initialAdminPassword
   15  cd /var/lib/jenkins/
   16  ll
   17  cd workspace/
   18  ll
   19  cd RAHAM/
   20  ll
   21  ll target/
   22  cd
   23  cd /var/lib/jenkins/workspace/abcd/
   24  ll
   25  ll target/
   26  mvn -v
   27  java -version
   28  cd
   29  ll
   30  mkdir raham
   31  cd raham/
   32  ll
   33  pwd
   34  cd /
   35  ll
   36  chown jenkins:jenkins /root/
   37  ll
   38  cd /root/
   39  ll
   40  chown jenkins:jenkins raham/
   41  ll
   42  cd raham/
   43  ll
   44  cd
   45  mkdir swiggy
   46  cd swiggy/
   47  pwd
   48  chown jenkins:jenkins /root/
   49  chown jenkins:jenkins /root/swiggy
   50  cd
   51  ll
   52  cd swiggy/
   53  ll
   54  cd
   55  yum remove maven java* -y
   56  yum install maven -y
   57  mvn -v
   58  cd swiggy/
   59  mvn compile
   60  mvn -v
   61  ll
   62  history
================================================================================
SETTING CI SERVER USING SCRIPT:

CREATE A SERVER
sudo -i 

vim jenkins.sh

#STEP-1: INSTALLING GIT JAVA-1.8.0 MAVEN 
yum install git java-1.8.0-openjdk maven -y

#STEP-2: GETTING THE REPO (jenkins.io --> download -- > redhat)
sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key

#STEP-3: DOWNLOAD JAVA11 AND JENKINS
amazon-linux-extras install java-openjdk11 -y
yum install jenkins -y
update-alternatives --config java

#STEP-4: RESTARTING JENKINS (when we download service it will on stopped state)
systemctl start jenkins.service
systemctl status jenkins.service

:wq

To run script: sh jenkins.sh

To execute commands on jenkins use execute shell under build steps.

VARIABLES:
it is used to store values that are going to change frequently.
ex: date, season -----

TYPES OF VARIABLES IN JENKINS:
1. USER DEFINED
2. JENKINS ENV

1. USER DEFINED VARIABLES: these are defined by user
a. Local Variable: Variable will work inside of job.
will be working for only single job.

NEW ITEM -- > NAME: ABC -- > FREESTYLE -- > OK -- > BUILD -- >EXECUTE SHELL

name=raham
echo "hai all my name is $name, $name is from hyderabad, $name is teaching devops"


b. Global Variable: Variable will work outside of job.
will be working for multiple job.


Dashboard -- > Manage Jenkins -- > System -- > Global properties  -- > Environment variables -- > add : Name: name value: raham -- > save 

NOTE: while defining variables spaces will not be given.
local variables will be high priority.

Limitation: some values cant be defined by user because these values will change build by build.
ex: build number, time, name, url -----

2. JENKINS ENV VARIABLES: these are defined by Jenkins itself.
a. these variables can be change from build to build.
b. these variables will be on upper case.
c. these variables can be defined only once.

echo "the build number is $BUILD_NUMBER, the job name is $JOB_NAME"

printenv: gives all env vars of jenkins



find / -name jenkins.service
find command used to find the path of a file.

ADMIN TASKS:
1. CHANGING PORT NUMBER OF JENKINS:

vim /usr/lib/systemd/system/jenkins.service
line-70: 8080=8090 -- > save and exit
systemctl daemon-reload
systemctl restart jenkins.service

When we chnage configuration of any service we need to restart.

2. PASSWORDLESS LOGIN

vim /var/lib/jenkins/config.xml
line-10: true=false
systemctl restart jenkins.service

now check the jenkins dashboard it wont ask password


3. HOW TO RESOLVE THE ISSUE IF JENKINS SERVER CRASHED ?
stop the jenkins server and start it 
systemctl restart jenkins

When we stop server the services will be also stopped
so we want to restart them 

systemctl stop jenkins.service
systemctl restart Jenkins.service


BUILD EXECUTORS & PARALLEL BUILDS:
Jenkins will run the jobs sequentially (one by one)
if i want to run multiple builds at same time we can configure like this

job -- > configure -- > Execute concurrent builds if necessary -- > save -- > build now 2 times
now we can see 2 jobs will be running on same time.

BUILD EXECUTORS: max number of builds we can run
build-executor status -- > Built-In Node -- > Configure -- > 2 - 5 -- >save
now build 5 times


HISTORY:
    1  vim jenkins.sh
    2  sh jenkins.sh
    3  cat /var/lib/jenkins/secrets/initialAdminPassword
    4  cd /var/lib/jenkins/workspace/abcd/
    5  ll
    6  ll target/
    7  echo "my name is raham, raham is working on tcs and raham is teaching devops"
    8  echo "hai"
    9  cd
   10  find / -name jenkins.service
   11  find / -name .java
   12  find / -name jenkins.service
   13  vim /usr/lib/systemd/system/jenkins.service
   14  systemctl daemon-reload
   15  systemctl restart jenkins.service
   16  find / -name jenkins.service
   17  vim /usr/lib/systemd/system/jenkins.service
   18  systemctl daemon-reload
   19  systemctl restart jenkins.service
   20  vim /var/lib/jenkins/config.xml
   21  systemctl restart jenkins.service
   22  systemctl status jenkins.service
   23  systemctl start jenkins.service
   24  systemctl status jenkins.service
   25  history

===============================================

CRON JOB: We can schedule the jobs that need to be run at particular intervals.
here we use cron syntax
cron syntax has * * * * *
each * is separated by space

*	: minutes
*	: hours
*	: date
*	: month
*	: day of week (sun=0, mon=1 ----)

30 19 15 3 5

00 5 16 3 6

35 11 16 3 6

create a ci job -- > Build Triggers -- > Build periodically -- > * * * * * -- > save

CRONTAB-GENERATOR: https://crontab-generator.org/

limitation: it will not check the code is changed or not.


POLL SCM: 
in pollscm we will set time limit for the jobs.
if dev commit the code it will wait until the time is done.
in given time if we have any changes on code it will generate a build

create a ci job -- > Build Triggers -- > poll scm -- > * * * * * -- > save
commit the changes in GitHub then wait for 1 min.

LIMITATION:
1. in pollscm, we need to wait for the time we set.
2. we will get the last commit only.

WEBHOOK: it will trigger build the moment we change the code.
here we need not to wait for the build.

repo -- > settings -- > webhooks -- > add webhook -- > Payload URL (jenkins url) -- > http://35.180.46.134:8080/github-webhook/  -- > Content type -- > application/json -- > add

create ci job -- > Build Triggers: GitHub hook trigger for GITScm polling -- > save

BUILD SCRIPTS: to make jenkins builds from remote loc using script/
give token 
give url on other browser.

THROTTLE BUILD:

To restrict the builds in a certain time or intervals.
if we dont rsetrict due to immediate builds jenkins might crashdown.

by default jenkins will not do concurrent builds.
we need to enable this option in configuration.

Execute concurrent builds if necessary -- > tick it

create a ci job -- > configure -- > Throttle builds -- > Number of builds: 3 -- > time period : hours -- > save

now it will take 20  mins of gap for each build.

LINKEDJOB: ONE JOB WILL BUILD AFTER OTHER JOB IS BUILD.
UPSTREAM
DOWNSTRAM

UI CHANGING:
Manage Jenkins –>  Plugins -- >  avilable plugins -- > simple theme plugin.
Manage Jenkins –> Appearance -- >  CSS url and copy the below
         https://cdn.rawgit.com/afonsof/jenkins-material-theme/gh-pages/dist/material-cyan.css
     3. save and check the color.

BLUE OCEAN: to enhance the jenkins dashboard.

Dashboard -- > Manage Jenkins -- > Plugins -- > Available plugins -- > Blue Ocean -- > select -- > install -- > Go back to the top page -- > 


====================================================================================
16-03-2024:

NOTE: if we stop server then services inside server also going to stop.
chkconfig jenkins on
the above command will restart the jenkins service all the time.

PIPELINE: STEP BY EXECUTION OF A PROCESS
SERIES OF EVENTS INTERLINKED WITH EACHOTHER.
code -- > build -- > test -- > artifact -- > deployment

why to use ?
to automate the work.
to have clarity about the stage.

TYPES:
1. DECLARATIVE
2. SCRIPTED

pipeline syntax:
to write the pipeline we use DSL.
We use Groovy Script for jenkins Pipeline.
it consists of blocks that include stages.
it includes () & {} braces.


SHORTCUT: PASSS

P	: PIPELINE
A	: AGENT
S	: STAGES
S	: STAGE
S	: STEPS 


SINGLE STAGE: this pipeline will have only one stage.

EX-1:
pipeline {
    agent any 
    
    stages {
        stage('abc') {
            steps {
               sh 'touch file1'
            }
        }
    }
}

EX-2:
pipeline {
    agent any 
    
    stages {
        stage('raham') {
            steps {
                sh 'touch file2'
            }
        }
    }
}

MULTI STAGE: this pipeline will have more than one stage.

pipeline {
    agent any
    
    stages {
        stage ('two') {
            steps {
                sh 'touch file2'
            }
        }
        stage ('three') {
            steps {
                sh 'lscpu'
            }
        }
        stage ('four') {
            steps {
                sh 'lsmem'
            }
        }
    }
}


CI PIPELINE:

CODE + BUILD + TEST + ARTIFACT

pipeline {
    agent any
    
    stages {
        stage ('checkout') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
            }
        }
        stage ('build') {
            steps {
                sh 'mvn compile'
            }
        }
        stage ('test') {
            steps {
                sh 'mvn test'
            }
        }
        stage ('artifact') {
            steps {
                sh 'mvn package'
            }
        }
    }
}


PIPELINE AS A CODE: Running more than one command/action inside a single stage.
to reduce the length of the code.
to save the time.

pipeline {
    agent any
    
    stages {
        stage ('checkout') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
                sh 'mvn compile'
                sh 'mvn test'
                sh 'mvn package'
            }
        }
    }
}

MULTIP STAGE PIPELINE AS A CODE: Running more than one command/action in multiple stages.


pipeline {
    agent any
    
    stages {
        stage ('one') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
                sh 'mvn compile'
            }
        }
        stage ('two') {
            steps {
                sh 'mvn test'
                sh 'mvn package'
            }
        }
    }
}

PAAC OVER SINGLE SHELL: Running all the shell commands on a single shell.

pipeline {
    agent any
    
    stages {
        stage ('one') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
                sh '''
                mvn compile
                mvn test
                mvn package
                '''
            }
        }
    }
}


INPUT PARAMETERS: BASED ON USER INPUT THE PIPELINE IS GOING TO EXECUTE.

pipeline {
    agent any
    
    stages {
        stage ('checkout') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
            }
        }
        stage ('build') {
            steps {
                sh 'mvn compile'
            }
        }
        stage ('test') {
            steps {
                sh 'mvn test'
            }
        }
        stage ('artifact') {
            steps {
                sh 'mvn package'
            }
        }
        stage ('deploy') {
            input {
                message "is your inputs correct ?"
                ok "yes"
            }
            steps {
                echo "my code is deployed"
            }
        }
    }
}


BLUE OCEAN: used to change jenkins theme for better vizualization

DIFF BLW SCRIPTED VS DECLARATVE

SCRIPTED: 	DECLARATIVE: 
SHORT   	LONG
NO STAGES       IT HAS STAGES
START NODE      START WITH PIPELINE

===================================================================================

MASTER AND SLAVE:
it is used to distribute the builds.
it reduce the load on jenkins server.
communication blw master and slave is ssh.
Here we need to install agent (java-11).
slave can use any platform.
label = way of assingning work for slave.

SETUP:
#STEP-1 : Create a server and install java-11
amazon-linux-extras install java-openjdk11 -y

#STEP-2: SETUP THE SLAVE SERVER
Dashboard -- > Manage Jenkins -- > Nodes & Clouds -- > New node -- > nodename: abc -- > permanaent agent -- > save 

CONFIGURATION OF SALVE:

Number of executors : 3 #Number of Parallel builds
Remote root directory : /tmp #The place where our output is stored on slave sever.
Labels : swiggy #place the op in a particular slave
useage: last option
Launch method : last option 
Host: (your privte ip)
Credentials -- > add -- >jenkins -- > Kind : ssh username with privatekey -- > username: ec2-user 
privatekey : pemfile of server -- > save -- > 
Host Key Verification Strategy: last option

DASHBOARD -- > JOB -- > CONFIGURE -- > RESTRTICT WHERE THIS JOB RUN -- > LABEL: SLAVE1 -- > SAVE

BUILD FAILS -- > WHY -- > WE NEED TO INSTALL PACKAGES
yum install git java-1.8.0-openjdk maven -y


pipeline {
    agent {
        label 'two'
    }
    
    stages {
        stage('one') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
                sh '''
                mvn compile
                mvn test
                mvn package
                mvn install
                mvn clean package
                '''
            }
        }
    }
}


======================================================
POST BUILD ACTIONS:
Actions that perform after build is done.


1. always	: executes always
2. success	: executes when build is success only
3. failure	: executes when build is failed only


pipeline {
    agent any
    
    stages {
        stage('checkout') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
            }
        }
        stage('compile') {
            steps {
                sh 'mvn compile'
            }
        }
        stage('test') {
            steps {
                sh 'mvn test'
            }
        }
        stage('Artifacts') {
            steps {
                sh 'mvn clean package'
            }
        }
    }
    post {
        always {
            echo "this build is completed"
        }
    }
}


NEXUS:
Its an Artifactory storage service.
used to store artifacts on repo.
Nexus server -- > Repo -- > Artifact
we can use this server to rollback in real time.
it req t2.medium 
nexus uses java-1.8.0
PORT: 8081

ALTERTAVIVES: JFROG, S3, -----

STEPS: signin -- > username: admin & passowrd: /app/sonatype-work/nexus3/admin.password -- > next -- > set passowrd -- > disable ananamous access -- > save

CREATING REPO:
settings symobl -- > repositories -- > new -- > maven2(hosted) -- > name -- > save

NEXUS INTEGRATION TO PIPELINE:
1. Download the plugin (Nexus Artifact Uploader)
2. Configure it to pipeline by using pipeline syntax

NOTE: All the information will be available on pom.xml file.


PIPELINE:

pipeline {
    agent any
    
    stages {
        stage('checkout') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
            }
        }
        stage('build') {
            steps {
                sh 'mvn compile'
            }
        }
        stage('test') {
            steps {
                sh 'mvn test'
            }
        }
        stage('artifact') {
            steps {
                sh 'mvn package'
            }
        }
        stage('Artifact upload') {
            steps {
                nexusArtifactUploader artifacts: [[artifactId: 'NETFLIX', classifier: '', file: 'target/NETFLIX-1.2.2.war', type: '.war']], credentialsId: '968c23dd-b648-4f15-91bf-7d76981a1218', groupId: 'in.RAHAM', nexusUrl: '100.25.197.110:8081', nexusVersion: 'nexus3', protocol: 'http', repository: 'netflix', version: '1.2.2'
            }
        }
    }
}


TOMCAT:

WEBSITE: FRONTEND -- > DB IS OPT
WEBAPP: FRONTEND + BACKEND -- > DB IS MANDATORY

ITS A WEB APPLICATION SERVER USED TO DEPLOY JAVA APPLICATIONS.
AGENT: JAVA-11
PORT: 8080
WE CAN DEPLOY OUR ARTIFACTS.
ITS FREE AND OPENSOURCE
IT IS WRITTEN ON JAVA LANGUAGE.
YEAR: 1999 

war : tomcat/webapps
jar : tomcat/lib

ALTERNATIVES: NGINX, IIS, WEBSPHERE, JBOSS, GLASSFISH


SETUP: CREATE A NEW SERVER
INSTALL JAVA: amazon-linux-extras install java-openjdk11 -y

STEP-1: DOWNLOAD TOMCAT (dlcdn.apache.org)
wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.87/bin/apache-tomcat-9.0.87.tar.gz

STEP-2: EXTRACT THE FILES
tar -zxvf apache-tomcat-9.0.87.tar.gz

STEP-3: CONFIGURE USER, PASSWORD & ROLES
vim apache-tomcat-9.0.87/conf/tomcat-users.xml

 56   <role rolename="manager-gui"/>
 57   <role rolename="manager-script"/>
 58   <user username="tomcat" password="raham123" roles="manager-gui, manager-script"/>

STEP-4: DELETE LINE 21 AND 22
vim apache-tomcat-9.0.87/webapps/manager/META-INF/context.xml

STEP-5: STARTING TOMCAT
sh apache-tomcat-9.0.87/bin/startup.sh

CONNECTION:
COPY PUBLIC IP:8080 
manager apps -- > username: tomcat & password: raham123

===========================================================


PIPELINE FOR DEPLOYMENT:
1. CREATE A JENKINS SERVER
2. CREATE 2 SLAVE AND ATTACHED TO JENKINS (Master-slave)
3. INSTALL TOMCAT ON SLAVE 
4. CREATE NEXUS SERVER 
5. INSTALL DEPLOY TO CONTAINER PLUGIN
5. WRITE PIPELINE




pipeline {
    agent any
    
    stages {
        stage('checkout') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
            }
        }
        stage('build') {
            steps {
                sh 'mvn compile'
            }
        }
        stage('test') {
            steps {
                sh 'mvn test'
            }
        }
        stage('artifact') {
            steps {
                sh 'mvn package'
            }
        }
        stage('Nexus') { 
            steps {
                nexusArtifactUploader artifacts: [[artifactId: 'NETFLIX', classifier: '', file: 'target/NETFLIX-1.2.2.war', type: '.war']], credentialsId: '0398b1f2-7afc-4e8d-8ce8-9bfee980efb5', groupId: 'in.RAHAM', nexusUrl: '54.237.124.246:8081', nexusVersion: 'nexus3', protocol: 'http', repository: 'netflix', version: '1.2.2'
            }
        }
        stage('deploy') {
            steps {
                deploy adapters: [
                    tomcat9(
                        credentialsId: 'fe8240f3-e14b-4304-b4d9-d379a9b44188',
                        path: '',
                        url: 'http://3.94.205.96:8080/'
                    )
                ],
                contextPath: 'netflix',
                war: 'target/*.war'
            }
        }
    }
    post {
        success {
            sh 'printenv'
        }
    }
}


manage jenkins -- > credentials -- > add creds -- > username: tomcat & passowrd: raham123 -- > save
copy id and give to pipeline

==========================================================================

Automated: Deployment, Installation
Non-Automated: Server
To perform end-to-end automation we can use Ansible.
Creating servers
configure servers
deployment application on servers

ANSIBLE:
its a Configuration Management Tool.
Ansible is used to manage and work with multiple servers together.
its a free and Opensource.
Configuration: Hardware and Software 
Management: Pkgs update, installing, remove ----
it is used to automate the entire deployment process on multiple servers.
We install Python on Ansible.
we use a key-value format for the playbooks.

Jenkins = pipeline = groovy
ansible = playbooks = yaml


HISTORY:
in 2012 dev called Maichel Dehaan who developed ansible.
After few years RedHat taken the ansible.
it is platform-independent & will work on all linux flavours.


ARCHITECTURE:
PLAYBOOK: its a file which consist of code
INVENTORY: its a file which consist ip of nodes
SSH: used to connect with nodes
Ansible is Agent less.
Means no need to install any software on worker nodes.

SETUP: 
CREATE 5 SERVERS [1=ANSIBLE, 2=DEV, 2=TEST]

EXECUTE THE BELOW COMMANDS ON ALL SERVERS:
sudo -i
hostnamectl set-hostname ansible/dev-1/dev-2/test-1/test-2
sudo -i

passwd root  -- > to login to other servers
vim /etc/ssh/sshd_config (38 & 61 uncommnet both lines) 
systemctl restart sshd
systemctl status sshd
hostname -i

THE BELOW STEPS NEED TO BE RUN ON ANSIBLE SERVER:

amazon-linux-extras install ansible2 -y
yum install python3 python-pip python-dlevel -y

vim /etc/ansible/hosts
# Ex 1: Ungrouped hosts, specify before any group headers.
[dev]
172.31.20.40
172.31.21.25
[test]
172.31.31.77
172.31.22.114

ssh-keygen -- > enter 4 times 
ssh-copy-id root@private ip of dev-1 -- > yes -- > password -- > ssh private ip -- > ctrl d
ssh-copy-id root@private ip of dev-2 -- > yes -- > password -- > ssh private ip -- > ctrl d
ssh-copy-id root@private ip of test-1 -- > yes -- > password -- > ssh private ip -- > ctrl d
ssh-copy-id root@private ip of test-2 -- > yes -- > password -- > ssh private ip -- > ctrl d

ansible -m ping all : To check worker node connection with ansible server.

1. ADHOC COMMANDS:
these are simple Linux commands. 
these are used for temp works.
these commands will be over ridden.

ansible all -a "yum install git -y"
ansible all -a "yum install maven -y"
ansible all -a "mvn --version"
ansible all -a "touch file1"
ansible all -a "touch raham.txt"
ansible all -a "ls"
ansible all -a "yum install httpd -y"
ansible all -a "systemctl status httpd"
ansible all -a "systemctl start httpd"
ansible all -a "user add raham"
ansible all -a "cat /etc/passwd"
ansible all -a "yum remove git* maven* httpd* -y"


2. MODULES:
its a key-value pair.
modules are reusable.
we can use different modules for differnt purposes.
module flag is -m 

ansible all -m yum -a "name=git state=present"
ansible all -m yum -a "name=maven state=present"
ansible all -m yum -a "name=maven state=present"	[present=installed]
ansible all -m service -a "name=httpd state=started"	[started=resetart]
ansible all -m service -a "name=httpd state=stopped"	[stopped=stop]
ansible all -m yum -a "name=http state=absent"		[absent=uninstall]
ansible all -m user -a "name=vikram state=present"
ansible all -m user -a "name=vikram state=absent"
ansible all -m copy -a "src=raham.txt dest=/tmp"

Note: To remove a package completly with its dependencies use * 
ex: httpd*, git*

HISTORY:
    1  passwd root
    2  vim /etc/ssh/sshd_config
    3  systemctl restart sshd
    4  systemctl status sshd
    5  hostname -i
    6  amazon-linux-extras install ansible2 -y
    7  yum install python3 python-pip python-dlevel -y
    8  vim /etc/ansible/hosts
    9  ssh-keygen
   10  ll .sh
   11  ll .ssh
   12  ssh-copy-id root@172.31.30.229
   13  ssh 172.31.30.229
   14  ssh-copy-id root@172.31.28.181
   15  ssh 172.31.28.181
   16  ssh-copy-id root@172.31.22.44
   17  ssh 172.31.22.44
   18  ssh-copy-id root@172.31.24.236
   19  ssh 172.31.24.236
   20  ansible -m ping all
   21  ansible all -a  "yum install git -y"
   22  ansible all -a "yum install maven -y"
   23  ansible all -a "mvn -v"
   24  ansible all -a "ls"
   25  ansible all -a "touch file1"
   26  ansible all -a "ls"
   27  ansible all -a "yum remove git* -y"
   28  ansible all -a "git -v"
   29  ansible all -a "yum remove maven* -y"
   30  ansible all -a "mvn -v"
   31  ansible all -a "useradd raham"
   32  ansible all -a "cat /etc/passwd"
   33  ansible all -m yum -a "name=git state=present"
   34  ansible all -a "git -v"
   35  ansible all -m yum -a "name=maven state=present"
   36  ansible all -a "mvn -v"
   37  ansible all -m yum -a "name=httpd state=present"
   38  ansible all -m yum -a "name=httpd state=started"
   39  ansible all -m service -a "name=httpd state=started"
   40  ansible all -m service -a "name=httpd state=stopped"
   41  ansible all -m yum -a "name=httpd state=absent"
   42  ansible all -m user -a "name=vijay state=present"
   43  touch index.html
   44  ansible all -m copy -a "src=index.html dest=/tmp"
   45  ansible all -a "ls /tmp"
   46  history
===================================================================

3. PLAYBOOKS:
playbooks used to execute multiple modules.
we can reuse the playbook multiple times.
in real time we use a playbook to automate our work.
for deployment, pkg installation ----
here we use key-value pairs.
Key-Value can also be called as Dictionary.
ansible-playbook will be written on YAML syntax.
YAML = YET ANOTHER MARKUP LANGUAGE
extension for playbook is .yml or .yaml
playbook start with --- and end with ... (opt)


EX-1:

- hosts: all
  tasks:
    - name: installing git
      yum: name=git state=present

    - name: installing httpd
      yum: name=httpd state=present

    - name: starting httpd
      service: name=httpd state=started

    - name: create user
      user: name=jayanth state=present

    - name: copy a file
      copy: src=index.html dest=/root

    

TO EXECUTE: ansible-playbook playbbok.yml

Gather facts: it will get information of worker nodes
its by default task performed by ansible.

ok=total number of tasks
changed= no.of tasks successfully executed


EX-2:

- hosts: all
  ignore_errors: yes
  tasks:
    - name: uninstalling git
      yum: name=git* state=absent

    - name: uninstalling httpd
      yum: name=httpd* state=absent

    - name: starting httpd
      service: name=httpd state=started

    - name: create user
      user: name=jayanth state=absent

    - name: copy a file
      copy: src=index.html dest=/root

TO EXECUTE: ansible-playbook playbbok.yml
NOTE: By default ansible will execute the task in sequential manner if any certain task failed on the playbook it is going to stop the playbook execution so the remaining task will be on pending state that task will not be executed anymore for that purpose we can put ignore _errors in the playbook.


TAGS: by deafult ansible will execute all tasks sequantailly in a playbook.
we can use tags to execute a specific tasks or to skip a specic tasks.


EX-1:

- hosts: all
  ignore_errors: yes
  tasks:
    - name: installing git
      yum: name=git state=present
      tags: a

    - name: installing httpd
      yum: name=httpd state=present
      tags: b

    - name: starting httpd
      service: name=httpd state=started
      tags: c

    - name: create a user
      user: name=kohli state=present
      tags: d

    - name: copy a file
      copy: src=index.html dest=/tmp
      tags: e

SINGLE TAG: ansible-playbook raham.yml --tags d
MULTI TAGS: ansible-playbook raham.yml --tags b,c

EX-2:

- hosts: all
  ignore_errors: yes
  tasks:
    - name: uninstalling git
      yum: name=git* state=absent
      tags: a

    - name: uninstalling httpd
      yum: name=httpd state=absent
      tags: b

    - name: starting httpd
      service: name=httpd state=started
      tags: c

    - name: delete a user
      user: name=kohli state=absent
      tags: d

    - name: copy a file
      copy: src=index.html dest=/tmp
      tags: e

SKIP A SINGLE TASK: ansible-playbook raham.yml --skip-tags "c"
SKIP MULTIPLE TASK: ansible-playbook raham.yml --skip-tags "a,c"

VARIABLES:

STATIC VARS: we can define these vars inside the playbook and use for multiple times, once a variable is defined here it will not change untill we change.


- hosts: all
  vars:
    a: maven
    b: httpd
  tasks:
    - name: installing maven
      yum: name={{a}} state=present
    - name: installing httpd
      yum: name={{b}} state=present

TO EXECUTE: ansible-playbook playbbok.yml

DYNAMIC VARS: therse vars will be defined outside the playbook and these will change as per our requirments.

- hosts: all
  vars:
  tasks:
    - name: installing maven
      yum: name={{a}} state=absent
    - name: installing httpd
      yum: name={{b}} state=absent


ansible-playbook raham.yml --extra-vars "a=docker b=httpd"


LOOPS: We can use loops to reduce the length of the code for the playbook

- hosts: all
  tasks:
    - name: installing pkg-1
      yum: name={{item}} state=present
      with_items:
        - git
        - java-1.8.0-openjdk
        - maven
        - docker
        - httpd


ansible all -a "git -v"
ansible all -a "java -v"
ansible all -a "maven -v"
ansible all -a "docker -v"
ansible all -a "httpd -v"


- hosts: all
  tasks:
    - name: installing pkg-1
      yum: name={{item}} state=absent
      with_items:
        - git
        - java-1.8.0-openjdk
        - maven
        - docker
        - httpd

ansible all -a "git -v"
ansible all -a "java -v"
ansible all -a "maven -v"
ansible all -a "docker -v"
ansible all -a "httpd -v"

EX-2:

- hosts: all
  tasks:
    - name: creating users
      user: name={{item}} state=present
      with_items:
        - ravi
        - shiva
        - rajesh
        - shivani
        - luckyy


- hosts: all
  tasks:
    - name: creating users
      user: name={{item}} state=absent
      with_items:
        - ravi
        - shiva
        - rajesh
        - shivani
        - luckyy


HISTORY:
   49  ansible dev -a "ls"
   50  ansible all -a "ls"
   51  ansible dev -a "ls"
   52  ansible dev[0] -a "ls"
   53  ansible all -m yum -a "name=git state=present"
   54  ansible all -m yum -a "name=git* state=absent"
   55  vim raham.yml
   56  ansible-playbook raham.yml
   57  ll
   58  vim raham.yml
   59  ansible-playbook raham.yml
   60  vim m
   61  vim raham.yml
   62  ansible-playbook raham.yml
   63  vim raham.yml
   64  cat raham.yml
   65  ansible-playbook raham.yml --tags d
   66  ansible-playbook raham.yml --tags b,c
   67  vim raham.yml
   68  cat raham.yml
   69  ansible-playbook --skip-tags "c"
   70  ansible-playbook raham.yml --skip-tags "c"
   71  vim raham.yml
   72  vim abc.yml
   73  ansible-playbook abc.yml
   74  vim raham.yml
   75  ansible-playbook raham.yml
   76  vim raham.yml
   77  ansible-playbook raham.yml
   78  vim raham.yml
   79  ansible all -a "docker -v"
   80  ansible all -a "httpd -v"
   81  cat raham.yml
   82  ansible-playbook raham.yml --extra-vars "a=docker b=httpd"
   83  cat raham.yml
   84  sed -i 's/absent/present/g' raham.yml
   85  cat raham.yml
   86  ansible-playbook raham.yml --extra-vars "a=docker b=httpd"
   87  ansible all -a "httpd -v"
   88  ansible all -a "docker -v"
   89  cat raham.yml
   90  sed -i 's/present/absent/g' raham.yml
   91  cat raham.yml
   92  ansible-playbook raham.yml --extra-vars "a=docker b=httpd"
   93  vim raham.yml
   94  ansible-playbook raham.yml
   95  ansible all -a "git -v"
   96  ansible all -a "java -version"
   97  ansible all -a "docker -version"
   98  ansible all -a "docker -v"
   99  ansible all -a "mvn -v"
  100  ansible all -a "httpd -v"
  101  cat raham.yml
  102  sed -i 's/present/absent/g' raham.yml
  103  cat raham.yml
  104  ansible-playbook raham.yml
  105  ansible all -a "httpd -v"
  106  ansible all -a "mvn -v"
  107  ansible all -a "docker -v"
  108  ansible all -a "git -v"
  109  cat raham.yml
  110  vim raham.yml
  111  ansible-playbook raham.yml
  112  ansible all -a "cat /etc/passwd"
  113  cat raham.yml
  114  sed -i 's/present/absent/g' raham.yml
  115  ansible-playbook raham.yml
  116  ansible all -a "cat /etc/passwd"
  117  history


===========================================================================================

HANDLERS:
when we have two tasks in a single playbook if task 1 is depending upon task 2 so then we can use the concept called handlers .
once task one is executed successfully it will notify task 2 to perform the operation. 
the name of the notify and the name of the task two must be same.


- hosts: all
  tasks:
    - name: installing httpd
      yum: name=httpd state=present
      notify: starting httpd
  handlers:
    - name: starting httpd
      service: name=httpd state=started

sed -i 's/present/absent/g' raham.yml

- hosts: all
  tasks:
    - name: installing httpd
      yum: name=httpd state=absent
      notify: starting httpd
  handlers:
    - name: starting httpd
      service: name=httpd state=started

SETUP MODULE: used to print the complete info of worker nodes
ansible all -m setup 

ansible all -m setup  | grep -i family
ansible all -m setup  | grep -i pkg
ansible all -m setup  | grep -i cores



CONDITIONS:
CLUSTER: Group of servers
HOMOGENIUS: all servers have having same OS and flavour.
HETROGENIUS: all servers have different OS and flavour.

used to execute this module when we have different Clusters.

RedHat=yum
Ubuntu=apt

- hosts: all
  tasks:
    - name: installing git on RedHat
      yum: name=git state=present
      when: ansible_os_family == "RedHat"

    - name: installing git on Debian
      apt: name=git state=present
      when: ansible_os_family == "Debian"


SHELL VS COMMAND VS RAW:

- hosts: all
  tasks:
    - name: installing maven
      shell: yum install maven -y

    - name: installing httpd
      command: yum install httpd -y

    - name: installing docker
      raw: yum install docker -y

raw >> command >> shell.

ansible all -a "mvn -v"
ansible all -a "htppd -v"
ansible all -a "docker -v"


L	: LINUX
A	: APACHE
M	: MYSQL
P	: PYTHON


- hosts: all
  tasks:
    - name: installing apache
      yum: name=httpd state=present

    - name: installing mysql
      yum: name=mysql state=present

    - name: installing python
      yum: name=python3 state=present


 ansible all -a "httpd --version"
 ansible all -a "python3 --version"
 ansible all -a "mysql --version"



- hosts: all
  tasks:
    - name: installing httpd
      yum: name=httpd state=absent

    - name: installing python
      yum: name=python3 state=absent

    - name: installing mysql
      yum: name=mysql state=absent


STRATAGIES: Way of executing the playbook.

LINEAR: execute tasks sequencially 
if task-1 is executed on server-1 it will wait till task-2 execution

FREE: execute all tasks on all node at same time
if task-1 is executed on server-1 it wont wait till task-2 execution

ROLLING:
BATCH:


HISTORY:
  118  ansible all -m setup
  119  vim raham.yml
  120  ansible-playbook raham.yml
  121  sed -i 's/present/absent/g' raham.yml
  122  cat raham.yml
  123  ansible-playbook raham.yml
  124  ansible all -m setup
  125  ansible all -m setup | grep cpu -i
  126  ansible all -m setup | grep -i mem
  127  ansible all -m setup | grep -i family
  128  vim raham.yml
  129  ansible all -m setup | grep -i family
  130  ansible-playbook raham.yml
  131  sed -i 's/present/absent/g' raham.yml
  132  ansible-playbook raham.yml
  133  ansible all -m setup | grep -i family
  134  ansible all -m setup | grep -i node
  135  vim raham.yml
  136  ansible-playbook raham.yml
  137  vim raham.yml
  138  ansible-playbook raham.yml
  139  sed -i 's/present/absent/g' raham.yml
  140  ansible-playbook raham.yml
  141  vim raham.yml
  142  ansible-playbook raham.yml
  143  ansible all -a "git -v"
  144  ansible all -a "mvn -v"
  145  ansible all -a "tree -v"
  146  vim raham.yml
  147  ansible-playbook raham.yml
  148  ansible all -a "httpd -v"
  149  ansible all -a "python3 -v"
  150  ansible all -a "python3 --version"
  151  ansible all -a "mysql --version"
  152  sed -i 's/present/absent/g' raham.yml
  153  ansible all -a "mysql --version"
  154  ansible-playbook raham.yml
  155  vim m
  156  vim raham.yml
  157  history
============================================================
└── roles
    ├── pkgs
    │   └── tasks
    │       └── main.yml
    ├── users
    │   └── tasks
    │       └── main.yml
    └── webserver
        └── tasks
            └── main.yml


ROLES:
roles is a way of organizing playbooks in a structured format.
main purpose of roles is to encapsulate the data.
we can reuse the roles multiple times.
length of the playbook is decreased.
it contains on vars, templates, task -----
in real time we use roles for our daily activities.
yum install tree -y

mkdir playbooks
cd playbooks/

mkdir -p roles/pkgs/tasks
vim roles/pkgs/tasks/main.yml

- name: installing pkgs
  yum: name=git state=present
- name: install maven
  yum: name=maven state=present
- name: installing docker
  yum: name=docker state=present

mkdir -p roles/users/tasks
vim roles/users/tasks/main.yml

- name: create users
  user: name={{item}} state=present
  with_items:
    - uday
    - naveen
    - rohit
    - lokesh
    - saipallavi
    - supriya

mkdir -p roles/webserver/tasks
vim roles/web/tasks/main.yml

- name: installing httpd
  yum: name=httpd state=present

- name: starting httpd
  service: name=httpd state=started

cat master.yml

- hosts: all
  roles:
    - pkgs
    - users
    - webserver

find . -type f -exec sed -i 's/present/absent/g' {} \;


ANSIBLE GALAXY:

Ansible Galaxy is a  website where users can share roles and to a command-line tool for installing, creating, and managing roles.
Ansible Galaxy gives greater visibility to one of Ansible's most exciting features, such as application installation or reusable roles for server configuration. 
Lots of people share roles in the Ansible Galaxy.
Ansible roles consist of many playbooks, which is a way to group multiple tasks into one container to do the automation in a very effective manner with clean, directory structures.

ANSIBLE VAULT:
it is used to encrypt the files, playbooks ----
Technique: AES256 (USED BY FACEBOOK)
vault will store our data very safely and securely.
if we want to access any data which is in the vault we need to give a password.
Note: we can restrict the users to access the playbook aslo.

cat creds.txt
user=raham
passowrd=test123


ansible-vault create creds1.txt		: to create a vault
ansible-vault edit creds1.txt		: to edit a vault
ansible-vault rekey creds1.txt		: to change password for a vault
ansible-vault decrypt creds1.txt	: to decrypt the content	
ansible-vault encrypt creds1.txt	: to encrypt the content	
ansible-vault view creds1.txt		: to show the content without decrypt

PIP: its a pkg manager used to install python libs/modules

Redhat: yum
ubuntu: apt
python: pip

- hosts: all
  tasks:
    - name: install pip
      yum: name=pip state=present

    - name: installing NumPy
      pip: name=NumPy state=present

    - name: installing Pandas
      pip: name=Pandas state=present



STRATAGIES: Way of executing the playbook.

LINEAR: execute tasks sequencially 
if task-1 is executed on server-1 it will wait till task-2 execution
FREE: execute all tasks on all node at same time
if task-1 is executed on server-1 it wont wait till task-2 execution
ROLLING:
BATCH:

=================================================
DEBUG: to print the messages from a playbook.

- hosts: all
  tasks:
    - name: printing a msg
      debug:
        msg: hai all welcome to my session



NAME	: ansible_nodename
FAMILY  : ansible_os_family
PKG	: ansible_pkg_mgr
CPU	: ansible_processor_cores
MEM	: ansible_memtotal_mb
FREE	: ansible_memfree_mb


- hosts: all
  tasks:
    - name: printing a msg
      debug:
        msg: "my server name is :{{ansible_nodename}}, family is: {{ansible_os_family}}, packagemanager is : {{ansible_pkg_mgr}}, total cpus: {{ansible_processor_cores}}, total memory is : {{ansible_memtotal_mb}}, available mem is : {{ansible_memfree_mb}}"


LOOKUPS: this module used to get data from files, db and key values

- hosts: dev
  vars:
    a: "{{lookup('file', '/root/creds.txt') }}"
  tasks:
    - debug:
        msg: "hai my user name is {{a}}"

cat creds.txt
user=raham
password=test123

JINJA2 TEMPLATE: used to get the customized op, here its a text file which can extract the variables and these values will change as per time.


ASYNCHRONOUS & POLLING ACTIONS:
for every task in  ansible we can set time limit
if the task is not performed in that time limit ansible will stop playbook execution
this is called as asynchronous and polling.

- hosts: all
  ignore_errors: yes
  tasks:
    - name: sleeping
      command: sleep 30
      async: 10
      poll: 20
    - name: install git
      yum: name=git state=present

WEB SERVER : TO SHOW THE APP : httpd  : 80  : /var/www/html
frontend code
APP SERVER : TO USE THE APP : Tomcat  : 8080  : tomcat/webapps
frontend code + backend code

COMMENTS:
in YAML syntax we have only single line comment we don't have multiline comments for it by default

DRY RUN:
Ansible Dry Run or Ansible Check mode feature is to validate your playbook before execution. 
If we execute the playbook with dry run it won't do any changes to the worker nodes.


TOMCAT SETUP FROM BELOW LINK:
https://github.com/RAHAMSHAIK007/all-setups.git

HISTORY:
 239  vim dep.yml
  240  ansible-playbook dep.yml
  241  cat dep.yml '
  242  cat dep.yml
  243  ansible all --list-hosts
  244  ansible dev --list-hosts
  245  ansible test --list-hosts
  246  cat .ssh/known_hosts
  247  ll
  248  vim tomcat.yml
  249  cat tomcat.yml
  250  vim tomcat-users.xml
  251  vim context.xml
  252  cat tomcat.yml
  253  ansible-playbook tomcat.yml
  254  history
==================================================================================

LINK FOR SCRIPTS & PLAYBOOKS : https://github.com/RAHAMSHAIK007/all-setups.git
LINK FOR PROJECT: https://github.com/devopsbyraham/jenkins-java-project.git

Install jenkins on ansible server and connect to dashboard

INTEGRTAING ANSIBE WITH JENKINS:

1. install ansible plugin
2. configure ansible tool 
manage jenkins -- > tools -- > ansible -- > name: ansible & Path to ansible executables directory: /usr/bin -- > save

3. SAMPLE STEP: ANSIBLE PLAYBOOK
Ansible tool: ansible -- > Playbook file path in workspace: /etc/ansible/playbook.yml -- > 
Inventory file path in workspace: /etc/ansible/hosts -- > SSH CREDS: give creds of ansible & worker nodes -- > Disable the host SSH key check -- > generate script

18.215.171.109:8080/

pipeline {
    agent any
    
    stages {
        stage('checkout') {
            steps {
                git 'https://github.com/devopsbyraham/jenkins-java-project.git'
            }
        }
        stage('build') {
            steps {
                sh 'mvn compile'
            }
        }
        stage('test') {
            steps {
                sh 'mvn test'
            }
        }
        stage('artifact') {
            steps {
                sh 'mvn package'
            }
        }
        stage('nexus upload') {
            steps {
                echo "artifact is uploaded to nexus"
            }
        }
        stage('deploy') {
            steps {
                ansiblePlaybook credentialsId: '959fbd45-dd0d-44d9-95e6-dc2c41c7c58e', disableHostKeyChecking: true, installation: 'ansible', inventory: '/etc/ansible/hosts', playbook: '/etc/ansible/playbook.yml', vaultTmpPath: ''
            }
        }
    }
}


cat playbook.yml
- hosts: all
  tasks:

    - name: task1
      copy:
        src: /var/lib/jenkins/workspace/pipeline/target/NETFLIX-1.2.2.war
        dest: /root/tomcat/webapps


TEST CASE:

ansiblePlaybook credentialsId: '959fbd45-dd0d-44d9-95e6-dc2c41c7c58e', disableHostKeyChecking: true, installation: 'ansible', inventory: '/etc/ansible/hosts', limit: '$server', playbook: '/etc/ansible/playbook.yml', vaultTmpPath: ''


PARAMETERS: CHOICE -- > VARIBALE NAME: server   VALUE: dev & test


REAL SCENARIOS:
port change:
vim /root/apache-tomcat-9.0.80/conf/server.xml (line 69)
sh /root/apache-tomcat-9.0.80/bin/shutdown.sh
sh /root/apache-tomcat-9.0.80/bin/startup.sh

passowrd:
vim apache-tomcat-9.0.80/conf/tomcat-users.xml
sh /root/apache-tomcat-9.0.80/bin/shutdown.sh
sh /root/apache-tomcat-9.0.80/bin/startup.sh

TROUBLESHOTING TYPES:

1. JENKINS LEVEL: DevOps team
A. SYNTAX MISTAKE
B. CONFIGURATION
C. PLUGIN 

2. SERVER LEVEL: DevOps
a. JAVA VERSION
b. SOFTWARE PKGS 
C. PORT ACCESS

3. CODE LEVEL: Developers
No troubleshooting from devops team.
We need to download the logs and send them to developers.


RBAC:
RBAC:
RBAC: ROLE BASE ACCESS CONTROL.
TO restrict the user PERMISSIONS in jenkins.

suresh	= fresher
raham	= exp 

STEP-1: USER CREATION
manage jenkins -- > users -- > create users -- > suresh: fresher 

STEP-2: PLUGIN DOWNLOADING
Dashboard
Manage Jenkins
Plugins
Available plugin
Role-based Authorization Strategy  

STEP-3: CONFIGURE THE PLUGIN
Dashboard
Manage Jenkins
Security
Authorization 
Role-based  Strategy  
SAVE

STEP-4: MANAGE AND ASSIGN USERS
manage roles -- > add -- > fresher & exp -- > fresher: overall read & exp: admin -- > save
assign roles -- > add user -- > rajesh: fresher -- > save

==============================================================================

APPLICATION: Collection of services 

MONOLITHIC: multiple services are deployed on single server with single database.
MICRO SERVICES: multiple services are deployed on multiple servers with multiple database.

BASED ON USERS AND APP COMPLEXITY WE NEED TO SELECT THE ARCHITECTURE.

FACTORS AFFECTIONG FOR USING MICRO SERVICES:
F-1: COST 
F-2: MAINTAINANCE

CONTAINERS:
its same as a server/vm.
it will not have any operating system.
os will be on images.
(SERVER=AMI, CONTAINER=IMAGE)
its free of cost and can create multiple containers.

DOCKER: 
Its an free & opensource tool.
it is platform independent.
used to create, run & deploy applications on containers.
it is introduced on 2013 by solomenhykes & sebastian phal.
We used GO laguage to develope the docker.
here we write files on YAML.
before docker user faced lot of problems, but after docker there is no issues with the application.
Docker will use host resources (cpu, mem, n/w, os).
Docker can run on any OS but it natively supports Linux distributions.

CONTAINERIZATION:
Process of packing an application with its dependencies.
ex: PUBG

APP= PUBG & DEPENDECY = MAPS
APP= CAKE & DEPENDECY = KNIFE

os level of virtualization.

VIRTUALIZATION:
able to create resouce with our hardware properties.

ARCHITECTURE & COMPONENTS:
client: it will interact with user
user gives commands and it will be executed by docker client

daemon: manages the docker components(images, containers, volumes)

host: where we install docker (ex: linux, windows, macos)

Registry: manages the images.

ARCHITECTURE OF DOCKER:
yum install docker -y    #client
systemctl start docker	 #client,Engine
systemctl status docker


COMMANDS:
docker pull ubuntu	: pull ubuntu image
docker images		: to see list of images
docker run -it --name cont1 ubuntu : to create a container
-it (interactive) - to go inside a container
cat /etc/os-release	: to see os flavour


apt update -y	: to update 
redhat=yum
ubuntu=apt
without update we cant install any pkg in ubuntu


apt install git -y
apt install apache2 -y
service apache2 start
service apache2 status

docker p q		: to exit container
docker ps -a		: to list all containers
docker attach cont_name	: to go inside container
docker stop cont_name	: to stop container
docker start cont_name	: to start container
docker pause cont_name	: to pause container
docker unpause cont_name: to unpause container
docker inspect cont_name: to get complete info of a container
docker rm cont_name	: to delete a container

STOP: will wait to finish all process running inside container
KILL: wont wait to finish all process running inside container

HISTORY:
    1  yum install docker -y
    2  docker version
    3  systemctl start docker
    4  systemctl status docker
    5  docker images
    6  docker pull amazonlinux
    7  docker images
    8  df -h
    9  cd /
   10  ll
   11  du -sh
   12  cd
   13  docker images
   14  docker run -it --name cont1 amazonlinux
   15  docker ps
   16  docker rm cont1
   17  docker stop cont1
   18  docker rm cont1
   19  docker ps
   20  docker pull ubuntu
   21  docker images
   22  docker run -it --name cont1  ubuntu
   23  docker ps
   24  docker stop cont1
   25  docker ps
   26  docker ps -a
   27  docker start cont1
   28  docker ps -a
   29  docker kill cont1
   30  docker ps
   31  docker ps -a
   32  docker start cont1
   33  docker ps -a
   34  docker pause cont1
   35  docker ps -a
   36  docker unpause cont1
   37  docker rm cont1
   38  docker kill cont1
   39  docker rm cont1
   40  docker ps -a
   41  docker rum -it --name cont1 ubuntu
   42  docker run -it --name cont1 ubuntu
   43  docker ps -a
   44  docker kill cont1
   45  docker ps -a
   46  docker start cont1
   47  docker ps -a
   48  docker attach cont1
   49  docker inspect cont1
   50  docker ps
   51  docker stop cont1
   52  docker ps
   53  docker ps -a
   54  docker attach cont1
   55  docker start cont1
   56  docker ps -a
   57  docker attach xont1
   58  docker attach cont1
   59  docker ps -a
   60  docker start cont1
   61  docker attach cont1
   62  docker ps -a
   63  history
=======================================================================

OS LEVEL OF VIRTUALIZATION:

docker pull ubuntu
docker run -it --name cont1 ubuntu
apt update -y
apt install mysql-server apache2 python3 -y
touch file{1...5}
apache2 -v
mysql-server --version
python3 --version
ls

ctrl p q

docker commit cont1 raham:v1
docker run -it --name cont2 raham:v1
apache2 -v
mysql-server --version
python3 --version
ls


DOCKERFILE:
it is an automation way to create image.
here we use components to create image.
in Dockerfile D must be Capiatl.
Components also capital.
This Dockerfile will be Reuseable.
here we can create image directly without container help.
Name: Dockerfile

docker rmi -f $(docker images -qa)
docker kill $(docker ps -qa)
docker rm $(docker ps -qa)

COMPONENTS:

FROM		: used to base image
RUN		: used to run linux commands (During image creation)
CMD		: used to run linux commands (After container creation)
ENTRYPOINT	: high priority than cmd
COPY		: to copy local files to conatiner
ADD		: to copy internet files to conatiner
WORKDIR		: to open req directory
LABEL		: to add labels for docker images
ENV		: to set env variables (inside container)
ARGS		: to pass env variables (outside containers)
EXPOSE		: to give port number


EX-1:
FROM ubuntu
RUN apt update -y
RUN apt install apache2 -y
RUN apt install mysql-server -y
RUN apt install python3 -y


docker build -t raham:v1 .
docker run -it --name cont1 raham:v1 

EX-2:
FROM ubuntu
RUN apt update -y
RUN apt install apache2 -y
RUN apt install mysql-server -y
RUN apt install python3 -y
RUN apt install tree -y
CMD apt install maven -y

docker build -t raham:v2 .
docker run -it --name cont2 raham:v2

EX-3:
FROM ubuntu
RUN apt update -y
COPY index.html /tmp
ADD https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.87/bin/apache-tomcat-9.0.87.tar.gz /tmp
WORKDIR /tmp

docker build -t raham:v3 .
docker run -it --name cont3 raham:v3

EX-4:

FROM ubuntu
RUN apt update -y
COPY index.html /tmp
ADD https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.85/bin/apache-tomcat-9.0.85.tar.gz /tmp
WORKDIR /tmp
EXPOSE 8080

docker build -t raham:v4 .
docker run -it --name cont4 raham:v4


EX-5:
FROM ubuntu
LABEL author rahamshaik
ENV client swiggy
ENV server appserver

docker build -t raham:v5 .
docker run -it --name cont5 raham:v5


CODE: https://www.w3schools.com/howto/tryit.asp?filename=tryhow_css_form_icon

Dockerfile For Deployment:

FROM ubuntu
RUN apt update -y
RUN apt install apache2 -y
COPY index.html /var/www/html
CMD ["/usr/sbin/apachectl", "-D", "FOREGROUND"]

docker build -t raham:v6 .
docker run -itd --name cont7 -p 82:80 raham:v6


/var/www/html -- > path to store frontend code for application


TO DELETE ALL CONTAINER:
docker ps -a	: to show all containers
docker ps -aq	: to show all container ids

docker stop $(docker ps -aq) : to stop all containers
docker rm $(docker ps -aq)   : to delete all containers

TO DELETE ALL IMAGES:
docker images -aq	: to show image ids
docker rmi -f $(docker images -aq) : to remove all images

JENKINS WITH DOCKER IMAGE:
docker run -it --name cont1 -p 8080:8080 jenkins/jenkins:lts

HISTORY:

    1  yum install docker -y
    2  docker version
    3  systemctl start docker
    4  systemctl status docker
    5  docker pull ubuntu
    6  docker run -it --name cont1 ubuntu
    7  docker attach cont1
    8  docker images
    9  docker ps -a
   10  docker commit cont1 raham:v1
   11  docker images
   12  docker run -it --name cont2 raham:v1
   13  docker images
   14  docker ps -a
   15  docker kill cont1 cont2
   16  docker rm cont1 cont2
   17  docker ps -a
   18  docker rmi -f raham:v1
   19  vim Dockerfile
   20  docker images
   21  docker ps -a
   22  docker build -t raham:v1 .
   23  docker images
   24  docker run -it --name cont1 raham:v1
   25  vim Dockerfile
   26  docker build -t raham:v2 .
   27  docker run -it --name cont2 raham:v2
   28  ll
   29  touch index.html
   30  vim Dockerfile
   31  docker build -t raham:v3 .
   32  docker run -it --name cont3 raham:v3
   33  vim Dockerfile
   34  docker build -t raham:v4 .
   35  docker run -it --name cont4 raham:v4
   36  docker ps -a
   37  vim Dockerfile
   38  docker build -t raham:v5 .
   39  docker run -it --name cont5 raham:v5
   40  docker inspect cont5
   41  vim Dockerfile
   42  vim index.html
   43  vim Dockerfile
   44  docker build -t raham:v6 .
   45  docker run -it --name cont6 -p 81:80 raham:v6
   46  docker ps -a
   47  docker run -itd --name cont7 -p 82:80 raham:v6
   48  docker ps -a
   49  docker ps -aq
   50  docker stop $(docker ps -aq)
   51  docker rm $(docker ps -aq)
   52  docker ps -a
   53  docker images
   54  docker images -aq
   55  docker rmi -f $(docker images -aq)
   56  docker images
   57  history
===============================================================

vim Dockerfile

FROM ubuntu
RUN apt update -y
RUN apt install apache2 -y
COPY index.html /var/www/html
CMD ["/usr/sbin/apachectl", "-D", "FOREGROUND"]

Index.html: take form w3 schools 

docker build -t movies:v1 .
docker run -itd --name movies -p 81:80 movies:v1

docker build -t train:v1 .
docker run -itd --name train -p 82:80 train:v1

docker build -t dth:v1 .
docker run -itd --name dth -p 83:80 dth:v1

docker build -t recharge:v1 .
docker run -itd --name recharge -p 84:80 recharge:v1

docker ps -a -q		: to list container ids
docker kill $(docker ps -a -q) : to kill all containers 
docker rm $(docker ps -a -q) : to remove all containers 

Note: In the above process all the containers are managed and created one by one in real time we manage all the continers at same time so for that purpose we are going to use the concept called Docker compose.



DOCKER COMPOSE:
It's a tool used to manage multiple containers in single host.
we can create, start, stop, and delete all containers together.
we write container information in a file called a compose file.
compose file is in YAML format.
inside the compose file we can give images, ports, and volumes info of containers.
we need to download this tool and use it.

INSTALLATION:
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
ls /usr/local/bin/
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose version


In Linux majorly you are having two type of commands first one is inbuilt commands which come with the operating system by default 
second one is download commands we are going to download with the help of yum, apt or Amazon Linux extras.

some commands we can download on binary files.

NOTE: linux will not give some commands, so to use them we need to download seperately
once a command is downloaded we need to move it to /usr/local/bin
because all the user-executed commands in linux will store in /usr/local/bin
executable permission need to execute the command



vim docker-compose.yml

version: '3.8'
services:
  movies:
    image: movies:v1
    ports:
      - "81:80"
  train:
    image: train:v1
    ports:
      - "82:80"
  dth:
    image: dth:v1
    ports:
      - "83:80"
  recharge:
    image: recharge:v1
    ports:
      - "84:80"

COMMANDS:
docker-compose up -d		: to create and start all containers
docker-compose stop		: to stop all containers
docker-compose start		: to start all containers
docker-compose kill		: to kill all containers
docker-compose rm		: to delete all containers
docker-compose down		: to stop and delete all containers
docker-compose pause		: to pause all containers
docker-compose unpause		: to unpause all containers
docker-compose ps -a		: to list the containers managed by compose file
docker-compose images		: to list the images managed by compose file
docker-compose logs		: to show logs of docker compose
docker-compose top		: to show the process of compose containers
docker-compose restart		: to restart all the compose containers
docker-compose scale train=10	: to scale the service


CHANGING THE DEFULT FILE:

by default the docker-compose wil support the following names
docker-compose.yml, docker-compose.yaml, compose.yml, compose.yaml

mv docker-compose.yml raham.yml
docker-compose up -d	: throws an error

docker-compose -f raham.yml up -d
docker-compose -f raham.yml ps
docker-compose -f raham.yml down


images we create on server.
these images will work on only this server.

git (local) -- > github (internet) = to access by others
image (local) -- > dockerhub (internet) = to access by others

Replace your username 

STEPS:
create dockerhub account
create a repo

docker tag movies:v1 vijaykumar444p/movies
docker login -- > username and password
docker push vijaykumar444p/movies


docker tag train:v1 vijaykumar444p/train
docker push vijaykumar444p/train


docker tag dth:v1 vijaykumar444p/dth
docker push vijaykumar444p/dth

docker tag recharge:v1 vijaykumar444p/recharge
docker push vijaykumar444p/recharge

docker rmi -f $(docker images -q)
docker pull vijaykumar444p/movies:latest



docker run --name mysql-db -e MYSQL_ROOT_PASSWORD=raham123 -d mysql:latest
docker exec -it mysql-db /bin/bash
mysql -u root -p
create database raham123;
show databases;
drop database raham123;


COMPRESSING IMAGES:
docker save rahamshaik/moviespayy -o abc.tar
gzip abc.tar abc.tar.gz
du -sh abc.tar.gz

HISTORY:

    1  yum install docker -y
    2  yum install docker -y
    3  systemctl start docker
    4  systemctl status docker
    5  vim Dockerfile
    6  vim index.html
    7  docker build -t movies:v1 .
    8  docker run -itd --name cont1 -p 81:80 movies:v1
    9  vim index.html
   10  docker build -t train:v1 .
   11  docker run -itd --name cont2 -p 82:80 train:v1
   12  vim index.html
   13  docker build -t recharge:v1 .
   14  docker run -itd --name cont3 -p 83:80 recharge:v1
   15  vim index.html
   16  docker build -t dth:v1 .
   17  docker run  -itd --name cont4 -p 84:80 dth:v1
   18  docker-compose
   19  docker ps -a
   20  docker kill $(docker ps -aq)
   21  docker rm $(docker ps -aq)
   22  docker ps -a
   23  sudo curl -L "https://github.com/docker/compose/releases/download/1.29.1/docker-compose-$(uname -s)-$(uname -m)" -o                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /usr/local/bin/docker-compose
   24  ls /usr/local/bin/
   25  sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
   26  sudo chmod +x /usr/local/bin/docker-compose
   27  docker-compose version
   28  docker-compose
   29  vim docker-compose.yml
   30  docker-compose up -d
   31  docker-compose ps -a
   32  docker ps -a
   33  docker-compose stop
   34  docker ps -a
   35  docker-compose start
   36  docker ps -a
   37  docker-compose pause
   38  docker ps -a
   39  docker-compose unpause
   40  docker-compose kill
   41  docker ps -a
   42  docker-compose rm
   43  docker ps -a
   44  docker-compose up -d
   45  docker ps -a
   46  docker images
   47  docker-compose images
   48  docker ps -a
   49  docker-compose ps -a
   50  docker run  -itd --name cont4 -p 84:80 dth:v1
   51  docker run  -itd --name cont4 -p 85:80 dth:v1
   52  docker ps -a
   53  docker-compose ps -a
   54  docker-compose logs
   55  docker-compose top
   56  docker-compose restart
   57  docker-compose scale train=10
   58  docker-compose ps -a
   59  ll
   60  mv docker-compose.yml raham.yml
   61  docker-compose kill
   62  docker-compose -f raham.yml kill
   63  docker-compose -f raham.yml rm
   64  docker-compose -f raham.yml up -d
   65  docker-compose -f raham.yml down
   66  docker images
   67  docker tag movies:v1 vijaykumar444p/movies
   68  docker images
   69  docker push vijaykumar444p/movies
   70  docker login
   71  docker push vijaykumar444p/movies
   72  docker tag train:v1 vijaykumar444p/train
   73  docker push vijaykumar444p/train
   74  docker tag dth:v1 vijaykumar444p/dth
   75  docker push vijaykumar444p/dth
   76  docker tag recharge:v1 vijaykumar444p/recharge
   77  docker push  vijaykumar444p/recharge
   78  docker images -q
   79  docker rmi -f $(docker images -q)
   80  docker images
   81  docker pull vijaykumar444p/movies:latest
   82  docker images
   83  docker run -it  -p 8888:8080 tomcat:9.0
   84  docker kil $(docker ps -q)
   85  docker kill $(docker ps -q)
   86  docker kill $(docker ps -aq)
   87  docker rm $(docker ps -aq)
   88  docker run -it  -p 8080:8080 tomcat:latest
   89  docker kill $(docker ps -aq)
   90  docker rm $(docker ps -aq)
   91  docker run -it --name cont1 -p 8080:8080  tomcat:jre21-temurin-jammy
   92  docker run --name mysql-db -e MYSQL_ROOT_PASSWORD=raham123 -d mysql:tag
   93  docker run --name mysql-db -e MYSQL_ROOT_PASSWORD=raham123 -d mysql:latest
   94  docker ps
   95  docker exec -it mysql-db /bin/bash
   96  docker images
   97  docker save vijaykumar444p/movies:latest -o abc.tar
   98  ls
   99  ll
  100  du -sh abc.tar
  101  gzip abc.tar abc.tar.gz
  102  du -sh abc.tar.gz
  103  history


==========================================================================================

High Avaliabilty: more than one server
why: if one server got deleted then other server will gives the app

DOCKER SWARM:
its an orchestration tool for containers. 
used to manage multiple containers on multiple servers.
here we create a cluster (group of servers).
in that clutser we can create same container on multiple servers.
here we have the manager node and worker node.
manager node will create & distribute the container to worker nodes.
worker node's main purpose is to maintain the container.
without docker engine we cant create the cluster.
Port: 2377
worker node will join on cluster by using a token.
manager node will give the token.



SETUP:
create 3 servers
install docker and start the service
hostnamectl set-hostname manager/worker-1/worker-2
Enable 2377 port 

docker swarm init (manager) -- > copy-paste the token to worker nodes
docker node ls

Note: individual containers are not going to replicate.
if we create a service then only containers will be distributed.

SERVICE: it's a way of exposing and managing multiple containers.
in service we can create copy of conatiners.
that container copies will be distributed to all the nodes.

service -- > containers -- > distributed to nodes

docker service create --name movies --replicas 3 -p 81:80 vijaykumar444p/movies:latest
docker service ls		: to list services
docker service inspect movies	: to get complete info of service
docker service ps movies	: to list the containers of movies
docker service scale movies=10	: to scale in the containers
docker service scale movies=3	: to scale out the containers
docker service rollback movies	: to go previous state
docker service logs movies	: to see the logs
docker service rm movies	: to delete the services.

when scale down it follows lifo pattern.
LIFO MEANS LAST-IN FIRST-OUT.

Note: if we delete a container it will recreate automatically itself.
it is called as self healing.


CLUSTER ACTIVIES:
docker swarm leave (worker)	: to make node inactive from cluster
To activate the node copy the token.
docker node rm node-id (manager): to delete worker node which is on down state
docker node inspect node_id	: to get comple info of worker node
docker swarm join-token manager	: to generate the token to join

Note: we cant delete the node which is ready state
if we want to join the node to cluster again we need to paste the token on worker node



DOCKER NETWORKING:
Docker networks are used to make communication between the multiple containers that are running on same or different docker hosts. 

We have different types of docker networks.
Bridge Network		: SAME HOST
Overlay network		: DIFFERENT HOST
Host Network
None network

BRIDGE NETWORK: It is a default network that container will communicate with each other within the same host.

OVERLAY NETWORK: Used to communicate containers with each other across the multiple docker hosts.

HOST NETWORK: When you Want your container IP and ec2 instance IP same then you use host network

NONE NETWORK: When you don’t Want The container to get exposed to the world, we use none network. It will not provide any network to our container.


To create a network: docker network create network_name
To see the list: docker network ls
To delete a network: docker network rm network_name
To inspect: docker network inspect network_name
To connect a container to the network: docker network connect network_name container_id/name
docker attach container_name 
apt update
apt install iputils-ping -y : command to install ping checks
ping ip-address of cont2

To disconnect from the container: docker network disconnect network_name container_name
To prune: docker network prune

HISTORY:
    1  docker swarm init
    2  docker node ls
    3  docker run -itd --name cont1 -p 81:80 vijaykumar444p/movies:latest
    4  docker ps
    5  docker ps -a
    6  docker kill cont1
    7  docker rm cont1
    8  docker service create --name movies --replicas 3 -p 81:80 vijaykumar444p/movies:latest
    9  docker ps
   10  docker ps
   11  docker service ps movies
   12  docker service ls
   13  docker service inspect movies
   14  docker service ps movies
   15  docker service logs  movies
   16  docker service scale movies=10
   17  docker service ps movies
   18  docker service scale movies=5
   19  docker service ps movies
   20  docker service rollback movies
   21  docker service ps movies
   22  docker service rollback movies
   23  docker service rm movies
   24  docker service ls
   25  docker service create --name paytm --replicas 3 -p 81:80 vijaykumar444p/movies:latest
   26  docker service ps movies
   27  docker service ps paytm
   28* docke3r node ls
   29  docker node ls
   30  docker node rm 7rkmw4szqu2xf49qwmmcw4a7b
   31  docker node ls
   32  docker node rm 111iguqw3y69eoj6emumbcygy
   33  docker node ls
   34  docker node rm 111iguqw3y69eoj6emumbcygy
   35  docker node ls
   36  docker swarm join token
   37  docker swarm join-token manager
   38  docker node ls
   39  docker node inspect lkkn7ur17ymcdcngef3xtprmr
   40  docker network ls
   41  docker service rm paytm
   42  docker network create raham
   43  docker network ls
   44  docker network inspect raham
   45  docker run -itd --name cont1 -p 81:80 vijaykumar444p/movies:latest
   46  docker run -itd --name cont2 -p 82:80 vijaykumar444p/movies:latest
   47  docker ps
   48  docker inspect $(docker ps -aq)
   49  docker network inspect raham
   50  docker network connect raham cont1
   51  docker network inspect raham
   52  docker network connect raham cont2
   53  docker network inspect raham
   54  docker exec -it cont1
   55  docker exec -it cont1 /bin/bash
   56  docker exec -it cont2 /bin/bash'
   57  docker exec -it cont2 /bin/bash
   58  docker network inspect raham
   59  docker network disconnect raham cont1
   60  docker network inspect raham
   61  history

